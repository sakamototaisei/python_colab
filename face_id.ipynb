{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakamototaisei/python_colab/blob/main/face_id.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXq1xV0wCsYT"
      },
      "source": [
        "# **顔認識の仕組み**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOt0EgIYERCd"
      },
      "source": [
        "## 画像認識とは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VxF47AlDtNW"
      },
      "source": [
        "*   画像認識とは、その画像が特定のカテゴリーのどれを表しているか識別すること\n",
        "*   SVM：決定教会を用いて分類する\n",
        "*   デープラーニングによる分類機で分類\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bekupZqMETyG"
      },
      "source": [
        "## 顔認識の方法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_dkaDZgEYI4"
      },
      "source": [
        "\n",
        "\n",
        "*   顔認識は、デジタル写真から検出された顔画像を、登録された人物と照合させて識別すること\n",
        "*   顔認証は、画像の人物が登録された人物と同一人物であるか判定して、公の期間が証明すること\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNbxXBTWFVAb"
      },
      "source": [
        "**顔認識の処理フロー**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJIhAHUcF-7p"
      },
      "source": [
        "## 顔の見分け方：ランドマーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSSp4n7KGGYd"
      },
      "source": [
        "\n",
        "\n",
        "*   顔の特徴を学習して距離を測る(目、眉、鼻、口、顎、etc...)\n",
        "*   68個のランドマークがある\n",
        "*   ランドマークの距離を測り比較し顔判定する\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8TMYZCMHHUz"
      },
      "source": [
        "# **顔検出の種類**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oIS7gG1HMCJ"
      },
      "source": [
        "## Haar-like特徴量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP7nKa8rHuIg"
      },
      "source": [
        "\n",
        "\n",
        "*   白と黒のパターンを組み合わせて特徴量を取得する\n",
        "*   長所：CPUでほぼリアルタイムに操作、画像サイズに関係なく顔を検出できる\n",
        "*   短所：顔でない場所も検出してしまう、露出の多い画像や正面画像以外は機能しない\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOef-v7PI6op"
      },
      "source": [
        "## Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W75hMycxI_OF"
      },
      "source": [
        "\n",
        "\n",
        "*   長所：他のモデルよりも正確、CPUでリアルタイムに実行、様々な顔向きに対応\n",
        "*   短所：処理が遅い、SSDで構成されているがソースは未公開\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pstxlgf2KVFQ"
      },
      "source": [
        "## HoG特徴量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_GGvjlkKafB"
      },
      "source": [
        "顔の部品(HoG特徴)を抽出\n",
        "\n",
        "*   分割されたセルから勾配の大きさと方向を計算\n",
        "*   ヒストグラムで特徴抽出\n",
        "*   抽出されたHoG特徴から、SVMで分類\n",
        "*   輝度の勾配方向をヒストグラム化した特徴量、物体の輪郭部分が強調されて確認できる\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAMf27d2LL5-"
      },
      "source": [
        "HoG特徴量\n",
        "\n",
        "*   Histograms of Oriented Gradientsは、画像の物体検出で使われる特徴記述子\n",
        "*   セルグリッド上から画像の局所的な輝度と輝度の勾配方向を計算\n",
        "*   その勾配方向を輝度分布のヒストグラムにしたものを特徴量とする\n",
        "*   画像スケールに対してロバスト\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AD5Wfo9MDUV"
      },
      "source": [
        "\n",
        "*   画像を31x31に区切る\n",
        "*   セル領域ごとに勾配を計算\n",
        "*   入力画像を水平方向、垂直方向に一次微微分フィルターで微分\n",
        "*   アークタンジェントでラジアンを算出して勾配方向を求める\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PVjiLUsObtk"
      },
      "source": [
        "度数変換：一次微分で微分された行と列の値をアークタンジェントでラジアンを計算\n",
        "\n",
        "ラジアンを角度に変換、角度を180度で割った時の余りを新しい角度とする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4A087auPMS0"
      },
      "source": [
        "水平方向、垂直方向に微分した値のノルムをとって、勾配の規模(強度)とする\n",
        "\n",
        "0~180度まで20度、9方向に分割"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahxBl4vAQHHi"
      },
      "source": [
        "\n",
        "\n",
        "*   長所：CPUで動作しDNNより高速、斜めでも機能する、軽量モデル、をしゅつの強い画像でも動作\n",
        "\n",
        "*   短所：最小の顔サイズが80x80で訓練される、下向きや上向きなどには機能しない\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVXMugmuRBjB"
      },
      "source": [
        "# **ブラウザで確認してみよう**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRnX3U7CvkuK"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrl95kXsKxJR",
        "outputId": "15e9e7de-16dd-4e2b-ec08-cbb8fce3be8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition==1.2.3\n",
            "  Downloading face_recognition-1.2.3-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from face_recognition==1.2.3) (1.21.6)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from face_recognition==1.2.3) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from face_recognition==1.2.3) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.8/dist-packages (from face_recognition==1.2.3) (19.24.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=7034b09b5be06ce1b245558aa77a4f8938f850754e7738af7c5b6d23a39a98fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/4b/8f/751e99d45f089bdf366a7d3e5066db3c2b84a62e4377f534d7\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.2.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dlib==19.18.0\n",
            "  Downloading dlib-19.18.0.tar.gz (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: dlib\n",
            "  Building wheel for dlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dlib: filename=dlib-19.18.0-cp38-cp38-linux_x86_64.whl size=4076397 sha256=ece72efc56546634c3ee68e3482eb82df1e86e092949ae25c1fdefd72eba209c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/51/5a/f7003b43977df5e50184bdefb95d7face592d75fb97ec5f8ce\n",
            "Successfully built dlib\n",
            "Installing collected packages: dlib\n",
            "  Attempting uninstall: dlib\n",
            "    Found existing installation: dlib 19.24.0\n",
            "    Uninstalling dlib-19.24.0:\n",
            "      Successfully uninstalled dlib-19.24.0\n",
            "Successfully installed dlib-19.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition==1.2.3\n",
        "!pip install dlib==19.18.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfzHaKRC35L5"
      },
      "source": [
        "## 顔を検出してみよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFQ0_Hn5KxG7"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "from PIL import Image, ImageDraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQSx-ZyVBcOv",
        "outputId": "e336e0f3-de73-41bf-bfb6-227e1aeb0c91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(741, 1380, 1891, 230)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "image = face_recognition.load_image_file(\"/content/sakatai.jpeg\")\n",
        "face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
        "face_locations # 右上(y1, x1), 左下(y2, x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJgfRf154h-e",
        "outputId": "d71f4b64-21cb-4996-ecb8-6a5a76f9b1e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[188, 188, 152],\n",
              "        [187, 187, 151],\n",
              "        [188, 188, 152],\n",
              "        ...,\n",
              "        [182, 173, 156],\n",
              "        [180, 171, 154],\n",
              "        [181, 172, 155]],\n",
              "\n",
              "       [[181, 181, 145],\n",
              "        [179, 179, 143],\n",
              "        [178, 178, 142],\n",
              "        ...,\n",
              "        [183, 174, 157],\n",
              "        [182, 173, 156],\n",
              "        [183, 174, 157]],\n",
              "\n",
              "       [[174, 174, 138],\n",
              "        [167, 167, 131],\n",
              "        [161, 161, 125],\n",
              "        ...,\n",
              "        [185, 176, 159],\n",
              "        [186, 177, 160],\n",
              "        [186, 177, 160]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 45,  41,  38],\n",
              "        [ 47,  43,  40],\n",
              "        [ 53,  49,  46],\n",
              "        ...,\n",
              "        [128, 112,  89],\n",
              "        [129, 113,  90],\n",
              "        [129, 113,  90]],\n",
              "\n",
              "       [[ 42,  38,  35],\n",
              "        [ 43,  39,  36],\n",
              "        [ 49,  45,  42],\n",
              "        ...,\n",
              "        [127, 111,  88],\n",
              "        [135, 119,  96],\n",
              "        [136, 120,  97]],\n",
              "\n",
              "       [[ 41,  37,  34],\n",
              "        [ 39,  35,  32],\n",
              "        [ 45,  41,  38],\n",
              "        ...,\n",
              "        [130, 114,  91],\n",
              "        [129, 113,  90],\n",
              "        [131, 115,  92]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VJ3BCey5MQs"
      },
      "outputs": [],
      "source": [
        "# 顔部分に枠をつける\n",
        "def face_detection(image, face_locations):\n",
        "    face_locations = (face_locations[0][1], face_locations[0][0], face_locations[0][3], face_locations[0][2])\n",
        "    im = Image.fromarray(image)\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    draw.rectangle(face_locations, fill=None, outline=(255, 0, 0), width=5)\n",
        "    return im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3k8P8Jt7Jb_"
      },
      "outputs": [],
      "source": [
        "face_detection(image, face_locations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dk7OsSs8jEb"
      },
      "source": [
        "## 類似度検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XVEgXA77aVC"
      },
      "outputs": [],
      "source": [
        "image1 = face_recognition.load_image_file('/content/sakatai.jpeg')\n",
        "image2 = face_recognition.load_image_file('/content/sakatai2.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FOe75sr971h"
      },
      "outputs": [],
      "source": [
        "encoding1 = face_recognition.face_encodings(image1)[0]\n",
        "encoding2 = face_recognition.face_encodings(image2)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAS0jzJf-GZZ",
        "outputId": "9cfa354f-8644-43e2-8b29-6de389280a3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "face_recognition.compare_faces([encoding1], encoding2, tolerance=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ar6pjGA_X18"
      },
      "source": [
        "## ランドマークの検出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5K-Tbtl-dRB"
      },
      "outputs": [],
      "source": [
        "def landmark_point(xy1, size=5):\n",
        "    xy2 = xy1[0]+size, xy1[1]+size\n",
        "    return [(xy1), (xy2)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = face_recognition.load_image_file('/content/sakatai.jpeg')\n",
        "face_landmark_list = face_recognition.face_landmarks(image)"
      ],
      "metadata": {
        "id": "pvGNS3Szz04r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.fromarray(image)\n",
        "draw = ImageDraw.Draw(im)\n",
        "\n",
        "for face_landmark in face_landmark_list[0]:\n",
        "    for xy in face_landmark_list[0][face_landmark]:\n",
        "        # 楕円を描くコマンド\n",
        "        draw.ellipse(landmark_point(xy, size=5), outline=(255, 0, 0), fill=(255, 0, 0))"
      ],
      "metadata": {
        "id": "KSuOoHSl1YPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im"
      ],
      "metadata": {
        "id": "bEtorhDr2o4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ランドマークのキーと値"
      ],
      "metadata": {
        "id": "U1SM-ocn21sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.fromarray(image)\n",
        "draw = ImageDraw.Draw(im)\n",
        "\n",
        "for face_landmark in face_landmark_list[0]:\n",
        "    print('face_landmark', face_landmark)\n",
        "    for xy in face_landmark_list[0][face_landmark]:\n",
        "        print('xy', xy)\n",
        "        # 楕円を描くコマンド\n",
        "        draw.ellipse(landmark_point(xy, size=5), outline=(255, 0, 0), fill=(255, 0, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arAlxNZS2ry7",
        "outputId": "628e3bfc-e7b5-4d7c-9455-44e55a56b7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face_landmark chin\n",
            "xy (243, 980)\n",
            "xy (250, 1126)\n",
            "xy (265, 1266)\n",
            "xy (293, 1397)\n",
            "xy (339, 1529)\n",
            "xy (412, 1647)\n",
            "xy (506, 1749)\n",
            "xy (617, 1833)\n",
            "xy (750, 1863)\n",
            "xy (880, 1843)\n",
            "xy (987, 1766)\n",
            "xy (1075, 1666)\n",
            "xy (1154, 1542)\n",
            "xy (1206, 1408)\n",
            "xy (1232, 1261)\n",
            "xy (1242, 1112)\n",
            "xy (1245, 969)\n",
            "face_landmark left_eyebrow\n",
            "xy (338, 871)\n",
            "xy (399, 794)\n",
            "xy (501, 776)\n",
            "xy (603, 794)\n",
            "xy (697, 839)\n",
            "face_landmark right_eyebrow\n",
            "xy (852, 863)\n",
            "xy (933, 814)\n",
            "xy (1028, 788)\n",
            "xy (1122, 803)\n",
            "xy (1170, 878)\n",
            "face_landmark nose_bridge\n",
            "xy (772, 972)\n",
            "xy (776, 1080)\n",
            "xy (779, 1183)\n",
            "xy (781, 1289)\n",
            "face_landmark nose_tip\n",
            "xy (662, 1347)\n",
            "xy (716, 1366)\n",
            "xy (774, 1382)\n",
            "xy (829, 1369)\n",
            "xy (882, 1352)\n",
            "face_landmark left_eye\n",
            "xy (449, 971)\n",
            "xy (504, 942)\n",
            "xy (574, 945)\n",
            "xy (633, 990)\n",
            "xy (569, 1006)\n",
            "xy (499, 1006)\n",
            "face_landmark right_eye\n",
            "xy (882, 999)\n",
            "xy (948, 955)\n",
            "xy (1019, 949)\n",
            "xy (1070, 975)\n",
            "xy (1023, 1015)\n",
            "xy (952, 1017)\n",
            "face_landmark top_lip\n",
            "xy (589, 1543)\n",
            "xy (660, 1505)\n",
            "xy (722, 1486)\n",
            "xy (775, 1505)\n",
            "xy (823, 1489)\n",
            "xy (874, 1512)\n",
            "xy (930, 1545)\n",
            "xy (899, 1546)\n",
            "xy (822, 1543)\n",
            "xy (773, 1546)\n",
            "xy (720, 1537)\n",
            "xy (623, 1542)\n",
            "face_landmark bottom_lip\n",
            "xy (930, 1545)\n",
            "xy (871, 1597)\n",
            "xy (822, 1621)\n",
            "xy (770, 1627)\n",
            "xy (714, 1620)\n",
            "xy (657, 1594)\n",
            "xy (589, 1543)\n",
            "xy (623, 1542)\n",
            "xy (718, 1545)\n",
            "xy (772, 1552)\n",
            "xy (821, 1546)\n",
            "xy (899, 1546)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USBを使ってみよう"
      ],
      "metadata": {
        "id": "C8L5bJW73Ov-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 顔の識別"
      ],
      "metadata": {
        "id": "ktmOEk203TW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定ファイルの読み込み\n",
        "import config\n",
        "threshold = config.threshold"
      ],
      "metadata": {
        "id": "ETyIBjHh3GHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顔情報の初期化\n",
        "face_locations = []\n",
        "face_encodings = []"
      ],
      "metadata": {
        "id": "ABm0Ijxl3enM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 登録画像の読み込み\n",
        "image_paths = glob.glob('image/*')\n",
        "image_paths.sort()\n",
        "know_face_encodings = []\n",
        "know_face_names = []\n",
        "checked_face = []"
      ],
      "metadata": {
        "id": "SyinG_ql5a42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# windows用(¥記号を2つ書く)\n",
        "# delimiter = \"¥¥\"\n",
        "\n",
        "# Mac用 / Linux用\n",
        "delimiter = \"/\"\n",
        "\n",
        "for image_path in image_paths:\n",
        "    # 拡張子を除いたファイル名を取り出している\n",
        "    im_name = image_path.split(delimiter)[-1].split('.')[0]\n",
        "    image = face_recognition.load_image_file(image_path)\n",
        "    face_encoding = face_recognition.face_encodings(image)[0]\n",
        "    know_face_encodings.append(face_encoding)\n",
        "    know_face_names.append(im_name)"
      ],
      "metadata": {
        "id": "g1fvYBVA6C5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_capture = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "e_ev1LRy5Gcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4T7Uz25l5_AN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MXq1xV0wCsYT",
        "YOt0EgIYERCd",
        "bekupZqMETyG",
        "xJIhAHUcF-7p",
        "v8TMYZCMHHUz"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNlrn4eJpTYsXijUOZQDeOn",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}