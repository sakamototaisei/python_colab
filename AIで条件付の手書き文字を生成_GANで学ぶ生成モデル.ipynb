{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2gAKkAdmNeOrxvkrLiarS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakamototaisei/python_colab/blob/main/AI%E3%81%A7%E6%9D%A1%E4%BB%B6%E4%BB%98%E3%81%AE%E6%89%8B%E6%9B%B8%E3%81%8D%E6%96%87%E5%AD%97%E3%82%92%E7%94%9F%E6%88%90_GAN%E3%81%A7%E5%AD%A6%E3%81%B6%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **生成モデルについて**"
      ],
      "metadata": {
        "id": "9UHCQUp4Oo1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **画像認識との違い：識別モデルと生成モデル**"
      ],
      "metadata": {
        "id": "sfVajhfKUCk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**識別モデル**\n",
        "\n",
        "*   入力情報/画像に対して、どのクラスであるか予測\n",
        "\n",
        "**生成モデル**\n",
        "\n",
        "*   入力情報に画像や乱数を与え→生成モデル→出力情報を生み出す"
      ],
      "metadata": {
        "id": "31ky4TWTUTUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **生成モデルの種類Part1_オートエンコーダー**"
      ],
      "metadata": {
        "id": "dB43CQwCVLLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**オートエンコーダー：自己符号化器**\n",
        "\n",
        "*   入力と出力が同じ値に\n",
        "*   ReLU関数により、事前学習は不要になった"
      ],
      "metadata": {
        "id": "kJVokKmgVX0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **生成モデルの種類Part2_VAE**"
      ],
      "metadata": {
        "id": "ySBAy1oWWCsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VAE：変分自己符号化器**\n",
        "\n",
        "*   出力が潜在変数によって決まる"
      ],
      "metadata": {
        "id": "ECFP_rl0WNPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **生成モデルの種類Part3_GAN**"
      ],
      "metadata": {
        "id": "tqIbseczZPGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAN：敵対的生成ネットワーク**\n",
        "\n",
        "*   「生成器」により偽物を生成し、本物と偽物を「識別器」によって判定する\n",
        "*   「生成器」の学習によって、「識別器」が正しく判断できなくなる出力0.5を目指す"
      ],
      "metadata": {
        "id": "tlzEiwI1Zm60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **様々なGAN**"
      ],
      "metadata": {
        "id": "tjLOkwQ6asp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **無垢に生まれたVanillaGAN**"
      ],
      "metadata": {
        "id": "MWm7TXZ9awFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   最もシンプルなGAN"
      ],
      "metadata": {
        "id": "GN44qaXde1Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **画像に強いDCGAN**"
      ],
      "metadata": {
        "id": "r32BWt02fEEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   上記のニューラルネットワークの部分を畳み込み層に置き換えたもの(識別器、生成器)\n",
        "*   解像度を4倍に増やしても、畳み込みの重み共有によりパラメータの数を減らすことができる、綺麗な画像を表現しつつ学習時間を短縮\n",
        "\n"
      ],
      "metadata": {
        "id": "sQc9viFaH3xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **条件付きのConditional GAN**"
      ],
      "metadata": {
        "id": "a6jQhevGJidt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   生成器や識別器に入力ノイズに条件を付ける、どの数字を生成しているのかなど"
      ],
      "metadata": {
        "id": "dDQWevx6JrfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **組み合わせのConditional DCGAN**"
      ],
      "metadata": {
        "id": "waaw471PKCYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   DCGANとConditionalv GANを組み合わせてもの"
      ],
      "metadata": {
        "id": "H-fgudP7KLk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **手書き文字を生み出そう：ソフトウェアコーディング**"
      ],
      "metadata": {
        "id": "HEhJJfLxLXmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ライブラリの読み込み**"
      ],
      "metadata": {
        "id": "bzxqqukILht3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Ez_31BaDavyQ"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "_5wBP2Rtasgh"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YDNAvhEmOwfF",
        "outputId": "f1662975-2bf9-4e5b-821f-c8f45a9f592f"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **データセットの読み込み**"
      ],
      "metadata": {
        "id": "dvl73iMcMri-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像サイズ\n",
        "img_size = 32\n",
        "\n",
        "# バッチサイズ、一度に学習できる画像の数になる\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "pMor2btDOwhk"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 読み込むデータの加工方式\n",
        "data_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5]) # RGBの場合は[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_datasets = datasets.MNIST(root='./datasets',\n",
        "                                train=True, download=True,\n",
        "                                transform=data_transforms)\n",
        "\n",
        "loaders = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "n21CXBDCOwkL"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(loaders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_gGS2lWOwmg",
        "outputId": "239150d0-ef01-4472-9f18-d841430f2587"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           ...,\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
              " \n",
              " \n",
              "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           ...,\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
              " \n",
              " \n",
              "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           ...,\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           ...,\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
              " \n",
              " \n",
              "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           ...,\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
              " \n",
              " \n",
              "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           ...,\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]),\n",
              " tensor([2, 7, 4, 2, 0, 4, 3, 2, 8, 2, 6, 2, 2, 4, 8, 0, 4, 8, 8, 9, 3, 3, 9, 5,\n",
              "         4, 8, 1, 4, 4, 7, 9, 7, 5, 1, 1, 0, 7, 7, 6, 2, 4, 0, 9, 6, 7, 3, 3, 9,\n",
              "         9, 0, 1, 5, 2, 3, 1, 2, 6, 0, 0, 8, 5, 6, 3, 1, 8, 6, 5, 3, 4, 3, 6, 5,\n",
              "         0, 2, 2, 0, 6, 9, 9, 6, 7, 1, 1, 4, 4, 4, 7, 7, 1, 6, 3, 5, 6, 3, 3, 3,\n",
              "         0, 5, 2, 4, 0, 0, 9, 7, 9, 8, 3, 4, 3, 8, 3, 8, 0, 1, 8, 0, 7, 8, 9, 3,\n",
              "         2, 2, 4, 2, 6, 3, 2, 2])]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像データの取得\n",
        "next(iter(loaders))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wON8GhrnOwpY",
        "outputId": "9b292e1b-2daf-4ce8-8302-231c5f27dd24"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **画像を表示させる**"
      ],
      "metadata": {
        "id": "UxHx_CsNPHmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def im_show(image):\n",
        "    print(image.shape)\n",
        "    mean = np.array([0.5, 0.5, 0.5])\n",
        "    std = np.array([0.5, 0.5, 0.5])\n",
        "    im = image.detach().numpy()\n",
        "    im = im.transpose(1, 2, 0) # c h w → h w c\n",
        "    # ノーマライゼーションの処理、暗い画像明るい画像を均等にする\n",
        "    im = std * im + mean\n",
        "    plt.imshow(im)"
      ],
      "metadata": {
        "id": "NKp0cULjPHgl"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_show(next(iter(loaders))[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "UVEy1Wx0PHbq",
        "outputId": "ea1cbede-3e5e-41c9-8fd9-97a2b1df4b3f"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **入力ノイズの生成**"
      ],
      "metadata": {
        "id": "Npp5Z1oxQoVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise(batch_size):\n",
        "    # torch.randn() 正規分布を自動生成してくれるメソッド\n",
        "    z = torch.randn((batch_size, 100, 1, 1)) # 正規乱数 -3.0 ~ 3.0\n",
        "    return z.cuda()"
      ],
      "metadata": {
        "id": "2H66bBxsPHZT"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_noise(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te0wL0IPPHXd",
        "outputId": "387256ad-a763-4d14-fda3-ab0c28af2b39"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.1245]],\n",
              "\n",
              "         [[-0.9080]],\n",
              "\n",
              "         [[-0.5031]],\n",
              "\n",
              "         [[-1.7367]],\n",
              "\n",
              "         [[ 1.2885]],\n",
              "\n",
              "         [[-0.5312]],\n",
              "\n",
              "         [[-0.5765]],\n",
              "\n",
              "         [[-1.4668]],\n",
              "\n",
              "         [[ 1.0399]],\n",
              "\n",
              "         [[ 1.1323]],\n",
              "\n",
              "         [[ 0.2333]],\n",
              "\n",
              "         [[-0.8714]],\n",
              "\n",
              "         [[-1.2953]],\n",
              "\n",
              "         [[-1.3717]],\n",
              "\n",
              "         [[-0.6865]],\n",
              "\n",
              "         [[-0.0298]],\n",
              "\n",
              "         [[ 0.0686]],\n",
              "\n",
              "         [[-0.4085]],\n",
              "\n",
              "         [[-0.6002]],\n",
              "\n",
              "         [[-0.5671]],\n",
              "\n",
              "         [[-1.1628]],\n",
              "\n",
              "         [[-1.0845]],\n",
              "\n",
              "         [[-0.6744]],\n",
              "\n",
              "         [[ 1.2884]],\n",
              "\n",
              "         [[ 0.1652]],\n",
              "\n",
              "         [[ 0.5442]],\n",
              "\n",
              "         [[ 2.0186]],\n",
              "\n",
              "         [[-1.3088]],\n",
              "\n",
              "         [[-1.6514]],\n",
              "\n",
              "         [[ 1.1790]],\n",
              "\n",
              "         [[ 1.0282]],\n",
              "\n",
              "         [[ 0.5331]],\n",
              "\n",
              "         [[-0.4104]],\n",
              "\n",
              "         [[ 0.0462]],\n",
              "\n",
              "         [[-0.2738]],\n",
              "\n",
              "         [[ 2.0798]],\n",
              "\n",
              "         [[-0.5912]],\n",
              "\n",
              "         [[-0.4462]],\n",
              "\n",
              "         [[ 0.2890]],\n",
              "\n",
              "         [[-1.6174]],\n",
              "\n",
              "         [[-1.2601]],\n",
              "\n",
              "         [[-0.9638]],\n",
              "\n",
              "         [[ 0.1830]],\n",
              "\n",
              "         [[ 0.9797]],\n",
              "\n",
              "         [[-0.2522]],\n",
              "\n",
              "         [[ 0.6161]],\n",
              "\n",
              "         [[-0.5052]],\n",
              "\n",
              "         [[-0.1238]],\n",
              "\n",
              "         [[-1.4847]],\n",
              "\n",
              "         [[-1.2447]],\n",
              "\n",
              "         [[ 0.6184]],\n",
              "\n",
              "         [[ 0.8621]],\n",
              "\n",
              "         [[ 0.0152]],\n",
              "\n",
              "         [[-1.3152]],\n",
              "\n",
              "         [[-0.2984]],\n",
              "\n",
              "         [[ 0.2140]],\n",
              "\n",
              "         [[ 1.3434]],\n",
              "\n",
              "         [[-1.1094]],\n",
              "\n",
              "         [[-2.9671]],\n",
              "\n",
              "         [[-0.8055]],\n",
              "\n",
              "         [[-0.6225]],\n",
              "\n",
              "         [[-0.1276]],\n",
              "\n",
              "         [[ 0.9592]],\n",
              "\n",
              "         [[ 0.1039]],\n",
              "\n",
              "         [[-0.5703]],\n",
              "\n",
              "         [[ 0.9939]],\n",
              "\n",
              "         [[-2.2318]],\n",
              "\n",
              "         [[ 0.9200]],\n",
              "\n",
              "         [[-0.6578]],\n",
              "\n",
              "         [[ 0.7923]],\n",
              "\n",
              "         [[-0.8258]],\n",
              "\n",
              "         [[-0.2362]],\n",
              "\n",
              "         [[-0.5429]],\n",
              "\n",
              "         [[ 0.0532]],\n",
              "\n",
              "         [[-1.2821]],\n",
              "\n",
              "         [[-1.4481]],\n",
              "\n",
              "         [[ 0.1599]],\n",
              "\n",
              "         [[ 0.4555]],\n",
              "\n",
              "         [[-1.0917]],\n",
              "\n",
              "         [[ 0.0102]],\n",
              "\n",
              "         [[ 0.0203]],\n",
              "\n",
              "         [[-0.4329]],\n",
              "\n",
              "         [[ 0.7011]],\n",
              "\n",
              "         [[-0.9297]],\n",
              "\n",
              "         [[-0.1424]],\n",
              "\n",
              "         [[-0.3135]],\n",
              "\n",
              "         [[ 1.2707]],\n",
              "\n",
              "         [[-0.8994]],\n",
              "\n",
              "         [[ 0.7752]],\n",
              "\n",
              "         [[-1.4312]],\n",
              "\n",
              "         [[-0.6422]],\n",
              "\n",
              "         [[-1.0453]],\n",
              "\n",
              "         [[-0.2466]],\n",
              "\n",
              "         [[ 2.0609]],\n",
              "\n",
              "         [[-0.6084]],\n",
              "\n",
              "         [[-1.9162]],\n",
              "\n",
              "         [[-0.4454]],\n",
              "\n",
              "         [[ 1.8916]],\n",
              "\n",
              "         [[ 1.2496]],\n",
              "\n",
              "         [[-0.5941]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = create_noise(1)\n",
        "print('max', z.max())\n",
        "print('min', z.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9_da0jlPHWA",
        "outputId": "73bae174-6d3e-4ecd-d62d-521cfba8b7d5"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max tensor(2.7233, device='cuda:0')\n",
            "min tensor(-2.6201, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **条件ラベルの生成**"
      ],
      "metadata": {
        "id": "Xgu8kQ_3R4Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成器に使う単位行列\n",
        "def create_1hot_vector():\n",
        "    label_1hots = torch.zeros(10, 10)\n",
        "    for i in range(10):\n",
        "        label_1hots[i, i] = 1\n",
        "    label_1hots = label_1hots.view(10, 10, 1, 1).cuda()\n",
        "    return label_1hots"
      ],
      "metadata": {
        "id": "4rKa2lL1PHTW"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成器に使う単位行列を生成\n",
        "label_1hots = create_1hot_vector()\n",
        "label_1hots.view(10, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czQoF607PHQj",
        "outputId": "f9db3289-0d17-42dd-f985-4006fb486eeb"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 識別器に使う単位行列\n",
        "def create_filled_label():\n",
        "    # 4次元の生成\n",
        "    label_fills = torch.zeros(10, 10, img_size, img_size)\n",
        "    # 画像のワンホットベクトル\n",
        "    ones = torch.ones(img_size, img_size)\n",
        "    for i in range(10):\n",
        "        label_fills[i][i] = ones\n",
        "    return label_fills.cuda()"
      ],
      "metadata": {
        "id": "EyhyarOqPHOW"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_fills = create_filled_label()\n",
        "label_fills[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOJ-5Ir4PHMD",
        "outputId": "dc940224-b843-4175-ab25-f1b8e394b588"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generatorの作成**"
      ],
      "metadata": {
        "id": "CTId54EbUym6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    # 初期化\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        # 入力チャンネルのベースとなる値を設定\n",
        "        d = 128\n",
        "        # 転置畳み込み\n",
        "        self.deconv1s = nn.ConvTranspose2d(100, d*2, kernel_size=4, stride=1, padding=0)\n",
        "        # 画像情報の偏りをなくす\n",
        "        self.deconv1s_bn = nn.BatchNorm2d(d*2)\n",
        "        # ターゲットラベル\n",
        "        self.deconv1t = nn.ConvTranspose2d(10, d*2, 4, 1, 0)\n",
        "        self.deconv1t_bn = nn.BatchNorm2d(d*2)\n",
        "        # ---　ここまでが入力層側のパラメータの設定 ---\n",
        "\n",
        "        # 第二層上記2つを足し合わせて2倍になっている\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d*2)\n",
        "        # 第三層\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d)\n",
        "        # 第四層\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, 1, 4, 2, 1)\n",
        "\n",
        "\n",
        "    # 重みの初期化\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # 順伝播処理\n",
        "    def forward(self, input_, label):\n",
        "        x = F.relu(self.deconv1s_bn(self.deconv1s(input_)))\n",
        "        y = F.relu(self.deconv1t_bn(self.deconv1t(label)))\n",
        "\n",
        "        # xとyをチャンネル方向に足し合わせる\n",
        "        x = torch.cat([x, y], 1)\n",
        "\n",
        "        # ２層目3層目4層目\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = torch.tanh(self.deconv4(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "5LsWa5PmPHKJ"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6anTBDbEOwrg",
        "outputId": "47926959-80d0-4c00-9f66-f4cbcc19ba61"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (deconv1s): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (deconv1s_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv1t): ConvTranspose2d(10, 256, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (deconv1t_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (deconv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (deconv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv4): ConvTranspose2d(256, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discriminatorの作成**"
      ],
      "metadata": {
        "id": "Et1mSJlma1x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # 入力チャンネルを64と指定\n",
        "        d = 64\n",
        "\n",
        "        # Generatorと逆のことをしてくイメージ\n",
        "        self.conv1s = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        # ターゲットラベル\n",
        "        self.conv1t = nn.Conv2d(10, d, 4, 2, 1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*4)\n",
        "\n",
        "        self.conv3 = nn.Conv3d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*8)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    # 重みの初期化\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # 順伝播\n",
        "    def forward(self, input_, label):\n",
        "        x = F.leaky_relu(self.conv1s(input_), 0.2) # leaky_relu 0.2\n",
        "        y = F.leaky_relu(self.conv1t(label), 0.2)\n",
        "        x = torch.cat([x, y], 1)\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = torch.sigmoid(self.conv4(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "93QrV8fdOwuI"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Discriminator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEu6IXDaQx9z",
        "outputId": "2c0a514f-c196-4a61-b566-3bb166e736ce"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1s): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv1t): Conv2d(10, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv3d(256, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "  (conv3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **重みの初期化**"
      ],
      "metadata": {
        "id": "VtpaIZWH93BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normal_init(m, mean, std):\n",
        "    # 転置畳み込みまたは畳み込みのモジュールであった場合に\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        # モジュールの重みのデータを正規化する\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        # バイアスを0に初期化している\n",
        "        m.bias.data.zero_()"
      ],
      "metadata": {
        "id": "Lb7zDn-gQx69"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = Generator()\n",
        "# Generatorの転置畳み込み1層目の画像の重みを取得\n",
        "w = sample.deconv1s.weight\n",
        "print('初期値', w.max())\n",
        "# 重みの初期化関数を呼び出す\n",
        "sample.weight_init(mean=0.0, std=0.02) # 0.0, 0.02\n",
        "print('変更後', w.max())\n",
        "\n",
        "# 重みが大きくなる"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuUTC10iQx41",
        "outputId": "8777025b-63ef-40d0-984d-098e73e28ca1"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期値 tensor(0.0156, grad_fn=<MaxBackward1>)\n",
            "変更後 tensor(0.0951, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **インスタンス化**"
      ],
      "metadata": {
        "id": "De2EWeevCKqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメーターとして学習係数を定義\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# 条件ラベルをインスタンス化\n",
        "label_1hots = create_1hot_vector()\n",
        "label_fills = create_filled_label()\n",
        "\n",
        "# 学習モデルをインスタンス化\n",
        "G = Generator().cuda()\n",
        "D = Discriminator().cuda()\n",
        "G.weight_init(mean=0.0, std=0.02)\n",
        "D.weight_init(mean=0.0, std=0.02)\n",
        "\n",
        "# 学習する上での最適化の処理を初期化する\n",
        "optimizer_G = torch.optim.Adam(G.parameters(), lr=learning_rate, betas=(0.5, 0.999)) # Adam 0.5, 0.999\n",
        "optimizer_D = torch.optim.Adam(D.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "\n",
        "# 損失関数を設定\n",
        "BCE_loss = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "7_pyKGgFQx1_"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminatorの教師ラベルを作成と自動微分化 Variable\n",
        "t_real = Variable(torch.ones(batch_size)).cuda()\n",
        "t_fake = Variable(torch.zeros(batch_size)).cuda()\n",
        "\n",
        "# 学習推移のログ\n",
        "loss_list = {}\n",
        "loss_list['loss_G'] = []\n",
        "loss_list['loss_D'] = []"
      ],
      "metadata": {
        "id": "NT27q1-LQx0C"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **学習ループ**"
      ],
      "metadata": {
        "id": "THTW8gTHFIdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパーパラメーターの設定\n",
        "epochs = 10\n",
        "\n",
        "# 継続の場合は、途中の番号を設定\n",
        "epoch_from = 1"
      ],
      "metadata": {
        "id": "RuCjA_KuQxx2"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch_from, epochs + 1):\n",
        "    print('epoch', epoch)\n",
        "    # 画像データとその画像がどの数字であったかというセットを取得\n",
        "    for i, (x_batch, t_batch) in enumerate(loaders): # x_betch, t_batch\n",
        "\n",
        "        # 取得したミニバッチのサイズ\n",
        "        N = len(x_batch)\n",
        "\n",
        "        label_1hot = label_1hots[t_batch]\n",
        "        label_fill = label_fills[t_batch]\n",
        "\n",
        "        # Generatorの損失を計算\n",
        "        # ノイズを作成\n",
        "        z =create_noise(N)\n",
        "        # 作り出したフェイク画像と、どの画像を作り出したかというラベルを与えて、これが本物であるか偽物であるか判定させる\n",
        "        fake = G(z, label_1hot)\n",
        "        # .squeeze()複雑な配列の要素を綺麗にまとまった形で成形して取り出す\n",
        "        pred = D(fake, label_fill).squeeze()\n",
        "        # 予測したpred変数が本当の値t_realとどれだけ誤差があるか計算\n",
        "        loss_G = BCE_loss(pred, t_real[0:, N])\n",
        "        loss_list['loss_G'].append(loss_G)\n",
        "\n",
        "        # Generatorの損失を元にパラメーターを更新\n",
        "        # 勾配を初期化\n",
        "        optimizer_G.zero_grad()\n",
        "        # 誤差逆伝播\n",
        "        loss_G.backward()\n",
        "        # パラメータの更新,\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Discriminatorの本物と偽物の損失をそれぞれ計算\n",
        "        # # 本物の損失を計算 本物の画像を取得\n",
        "        real = Variable(x_batch).cuda()\n",
        "        pred = D(real, label_fill).squeeze()\n",
        "        loss_D_real = BCE_loss(pred, t_real[0: N])\n",
        "\n",
        "        # 偽物の損失\n",
        "        z = create_noise(N)\n",
        "        # フェイク画像を取得\n",
        "        fake = G(z, label_1hot)\n",
        "        # ファいく画像をデタッチとして整形して入力する\n",
        "        pred = D(fake.detach(), label_fill).squeeze()\n",
        "        loss_D_fake = BCE_loss(pred, t_fake[0: N])\n",
        "\n",
        "        # 2つの損失を足し合わせる\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        loss_list['loss_D'].append(loss_D)\n",
        "\n",
        "        # Discriminatorのパラメーターを更新する\n",
        "        # 勾配を初期化\n",
        "        optimizer_D.zero_grad()\n",
        "        # 誤差逆伝播\n",
        "        loss_D.backward()\n",
        "        # パラメータの更新,\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # 100回に1度ログを表示させる\n",
        "        if i % 100 == 0:\n",
        "            print('G: %.4f D: %.4f' %(loss_G, loss_D))\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "    # 学習係数の減衰\n",
        "    if epoch == 5:\n",
        "        optimizer_G.param_groups[0]['lr'] = learning_rate/2\n",
        "        optimizer_D.param_groups[0]['lr'] = learning_rate/2\n",
        "    elif epoch == 7:\n",
        "        optimizer_G.param_groups[0]['lr'] = learning_rate/4\n",
        "        optimizer_D.param_groups[0]['lr'] = learning_rate/4\n",
        "    elif epoch == 9:\n",
        "        optimizer_G.param_groups[0]['lr'] = learning_rate/8\n",
        "        optimizer_D.param_groups[0]['lr'] = learning_rate/8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "fVhAjJZJQxvP",
        "outputId": "3eebcef6-933d-4e37-a728-0d873c4975ea"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-202-bdb13b830834>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcreate_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 作り出したフェイク画像と、どの画像を作り出したかというラベルを与えて、これが本物であるか偽物であるか判定させる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_1hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# .squeeze()複雑な配列の要素を綺麗にまとまった形で成形して取り出す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-193-076e7ea2db31>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, label)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv2_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv3_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    954\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             output_padding, self.groups, self.dilation)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv_transpose2d, but got input of size: [128, 128, 1, 1, 16, 16]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Te9tCaVSQxsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nle-AjfNQxqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaeVl-VIQxn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQ_rHjH3QxlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3eZkXVmQxi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-Nk2TLwOwwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4kagzI2OwzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}