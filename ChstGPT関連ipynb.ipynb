{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "gXtuGKS2wic1",
        "yf7igo1C0zme",
        "PLOEg5Nu3yUx",
        "LEdAlOHZ5i9B",
        "MDxrfUKtIhEH",
        "Qbd-aaOHNXmZ",
        "EV_YrgTE1mcQ",
        "bBM3YA2W5V7J",
        "95aSIzjyZhFt",
        "9fx_qoGricw3",
        "SrRCfwh-BYoL",
        "G0Ze2mjgF2sV"
      ],
      "authorship_tag": "ABX9TyNymxuRqTEUQrTrQfkClui+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakamototaisei/python_colab/blob/main/ChstGPT%E9%96%A2%E9%80%A3ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **セクション1：イントロ**"
      ],
      "metadata": {
        "id": "gXtuGKS2wic1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **OpenAIの簡単な歴史**"
      ],
      "metadata": {
        "id": "yf7igo1C0zme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   2015年に非営利団体として設立された→現在は営利団体企業となり大きな転換をする\n",
        "*   最先端の機械学習やAIの研究を行っている、GPT-4やDALL-E、Whisperのような非常に複雑なモデルを構築してる、フレームワークやAPIも開発\n",
        "*   2018年12月OpenAIは大規模言語モデルであるGPT-2を発表\n",
        "*   2019年営利企業へと変化する\n",
        "*   2020年6月にGPT-3をリリースする\n",
        "*   2020年12月にDALL-Eをリリース、画像生成モデル\n",
        "*   2022年11月にChat-GPTをリリース\n",
        "*   2023年3月にはChat APIを公開した\n",
        "\n"
      ],
      "metadata": {
        "id": "moEioPmS06Z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GPTについて**"
      ],
      "metadata": {
        "id": "PLOEg5Nu3yUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   テキストを渡してテキストを出力として得ることができる\n",
        "*   次の単語を予測するように学習されている"
      ],
      "metadata": {
        "id": "jsQUsEVY32E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transoformerアーキテクチャ**"
      ],
      "metadata": {
        "id": "LEdAlOHZ5i9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatGPT4に聞いてみた**\n",
        "\n",
        "**Transformerアーキテクチャとは？**\n",
        "\n",
        "Transformerは、自然言語処理のタスク、特に文章の翻訳や文章の生成などにおいて非常に優れた性能を示すニューラルネットワークの一種です。このアーキテクチャは「Attention Is All You Need」という論文で初めて紹介されました。名前が示す通り、「Attention」という概念が中心になっています。\n",
        "\n",
        "**Attention メカニズム**\n",
        "\n",
        "Attentionは、入力データのどの部分に注目すべきかをモデルに教える役割を持っています。たとえば、英語の文をフランス語に翻訳する際、Transformerは特定のフランス語の単語を生成するのに、英語の文のどの部分が重要かを判断します。\n",
        "\n",
        "**Transformerの主要な要素**\n",
        "\n",
        "1.  Encoder: Encoderは、入力データ（例：英語の文）をベクトルの形式で表現します。これにより、モデルが入力データの意味や構造を理解できるようになります。\n",
        "\n",
        "2.  Decoder: Decoderは、Encoderの出力を受け取り、ターゲットデータ（例：フランス語の文）を生成します。\n",
        "\n",
        "**どのように動作するのか？**\n",
        "\n",
        "1. Input Embedding: 入力文は単語ごとにベクトルに変換されます。これを埋め込みベクトルと呼びます。\n",
        "\n",
        "2. Positional Encoding: Transformerは、系列データの順序を理解する必要がありますが、自身には順序を表す情報がないため、位置情報を追加します。これがPositional Encodingです。\n",
        "\n",
        "3. Encoder Layers: これらのベクトルはEncoderに入ります。Encoderは複数の層で構成され、各層はSelf-AttentionとFeed Forward Neural Networkからなります。\n",
        "\n",
        "4. Decoder Layers: Encoderの出力はDecoderに送られます。Decoderも複数の層で構成されており、Encoderからの出力に注目しながら新しい単語を生成します。\n",
        "\n",
        "5. Output Linear Layer: Decoderの最後の層は、ターゲット言語の単語を生成します。\n",
        "\n",
        "**なぜTransformerは重要か？**\n",
        "\n",
        "Transformerアーキテクチャは並列処理に優れており、RNN(Recurrent Neural Networks) や LSTM (Long Short-Term Memory) と比べて、大規模なデータセットで高速に学習することができます。これにより、より大規模で複雑なNLPタスクに取り組むことができるようになりました。\n",
        "\n",
        "また、Attentionメカニズムによって、Transformerは系列データの中での関連性や依存関係を捉える能力が非常に高くなります。これにより、文の翻訳や文章生成において文脈や意味を考慮した結果を出力することができます。\n",
        "\n",
        "**Transformerを利用したモデル**\n",
        "\n",
        "Transformerアーキテクチャは非常に影響力があり、その後の多くのモデルの基盤となりました。代表的なものには以下のようなものがあります。\n",
        "\n",
        "* BERT (Bidirectional Encoder Representations from Transformers): BERTはTransformerのEncoderのみを使用し、テキストデータを深く理解することに焦点を当てています。BERTはテキストの分類、名前付きエンティティ認識、質問応答など、多くのNLPタスクで高い性能を発揮します。\n",
        "\n",
        "* GPT (Generative Pre-trained Transformer): GPTはTransformerのDecoder部分を使用して、テキストを生成することに特化しています。GPTは文章生成、文章の補完、文章の要約などのタスクで広く使用されています。\n",
        "\n",
        "**まとめ**\n",
        "\n",
        "Transformerアーキテクチャは、Attentionメカニズムを中心に、大規模なテキストデータを効率的に処理し、深い文脈理解を実現するためのニューラルネットワークです。これにより、NLPの分野における多くの進歩がもたらされ、BERTやGPTのような派生モデルも開発されました。これらのモデルは、自然言語処理の分野で広く使用され、高い性能を発揮しています。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TnHrIJCf5rw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3912u2KdIbQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **セクション2：始めよう**"
      ],
      "metadata": {
        "id": "MDxrfUKtIhEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **初めてのCompletionリクエスト**"
      ],
      "metadata": {
        "id": "Qbd-aaOHNXmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "VKp49np30zWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89dd2812-6a5b-4c3a-ac4a-bd188e8769b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **APIキーを隠そう**"
      ],
      "metadata": {
        "id": "EV_YrgTE1mcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   環境変数に入れる\n",
        "*   .envのような隠しファイルに入れる\n",
        "\n"
      ],
      "metadata": {
        "id": "btyfSp3M1y_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "id": "zNNWpB_Y00gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda6094a-7d6b-41d6-c94e-41be323c811b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import dotenv_values"
      ],
      "metadata": {
        "id": "tcAq3WSC00eM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "CFBvg-Uv4W_2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = dotenv_values('test.env')"
      ],
      "metadata": {
        "id": "qWMR34ju00cG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = config['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "O7nKWr8000XJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c3cea6a4-e5a8-46ae-a0a3-1228837240d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e79ac60c3b1e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.Completion.create(\n",
        "    model='text-davinci-003',\n",
        "    prompt='Happy Birthday '\n",
        ")"
      ],
      "metadata": {
        "id": "SRBeVqEf00Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **トークンについて**"
      ],
      "metadata": {
        "id": "bBM3YA2W5V7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   英語で4文字程度に分割される\n",
        "*   モデルに渡すトークン数が課金と関わる点が重要\n",
        "*   入力のトークン数と出力のトークン数の総数の合計を課金対象とする\n",
        "*   モデルによって価格は違い性能の良いモデルの方が高くなる"
      ],
      "metadata": {
        "id": "h2wBQcvlX1hA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **max_tokens**"
      ],
      "metadata": {
        "id": "95aSIzjyZhFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "JBF4YYYY00SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1273cb75-a809-40c7-ab64-2f1390916aaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "EC5DDO1ac3BT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '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'\n",
        "\n",
        "openai.Completion.create(\n",
        "    model='text-davinci-003',\n",
        "    prompt='The top 10 most populated cities are: ',\n",
        "    max_tokens=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDFTvylOc2-m",
        "outputId": "2ec1c880-b15d-497e-8529-5ed53aefb5fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7Xlu0IDdIPLOde81y4GJEAzvkZfqC at 0x7f1f4c905530> JSON: {\n",
              "  \"id\": \"cmpl-7Xlu0IDdIPLOde81y4GJEAzvkZfqC\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1688283316,\n",
              "  \"model\": \"text-davinci-003\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \"\\n\\n1. Tokyo\\n2. Delhi\\n3. Shanghai\\n4. Sao Paulo\\n5. Mexico City\\n6. Cairo\\n7. Los Angeles\\n8. Mumbai\\n9. Beijing\\n10. Dhaka\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 9,\n",
              "    \"completion_tokens\": 45,\n",
              "    \"total_tokens\": 54\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ストップシーケンス**"
      ],
      "metadata": {
        "id": "9fx_qoGricw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOlk7OT7c274",
        "outputId": "6b4b74ba-923d-4878-c904-e2221f104f88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model='text-davinci-003',\n",
        "    prompt='Generate a list of the best movies of all time ',\n",
        "    max_tokens=200,\n",
        "    stop='5.' # 最大４つまでの配列を設定してもOKで１つでも当てはまればそこで止まる\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD2rzmh1c25j",
        "outputId": "08151848-b826-4f00-cc30-06853fe556d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. The Godfather\n",
            "2. The Shawshank Redemption\n",
            "3. Schindler's List\n",
            "4. The Dark Knight\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **nとecho**"
      ],
      "metadata": {
        "id": "SrRCfwh-BYoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "7Ocwa7_dEl7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n**\n",
        "\n",
        "*   nで補完(completion)の数を指定することができ、デフォルトは1つなので結果も1つになる\n",
        "*   3にすると同じプロンプトに対して3つの異なる結果を得られる\n",
        "*   ユースケースとしては1つのプロンプトに対してtextに3つの答えが格納されていると大きなテキストデータとなり分割することも必要だし、どこで分割しなくてはいけないのかの判断も必要になる\n",
        "*   開発においてのレスポンスが扱いやすくなる\n",
        "*   nで指定していれば分割されて答えが出力される\n",
        "*   max_tokensなどの数値を分けて答えるようになる→コストが高くなりやすいので注意"
      ],
      "metadata": {
        "id": "rDGXSSrBBrvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model='text-davinci-003',\n",
        "    prompt='write me a poem ',\n",
        "    max_tokens=100,\n",
        "    n=3\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "fJ6tFZmrc22X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**echo**\n",
        "\n",
        "*   デフォルトはfalse、Trueで完了に加えてプロンプトをエコーバックする。\n",
        "*   **ここでエコーバックされたプロンプトに関してはコストはかからない**\n",
        "\n"
      ],
      "metadata": {
        "id": "HdEQS9abED3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model='text-davinci-003',\n",
        "    prompt='Q: What is the tallest building in the world? ',\n",
        "    max_tokens=100,\n",
        "    echo=True\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeEiTaXMc2Nk",
        "outputId": "37fb0447-63fd-4fb6-efc9-626f3f9c2812"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the tallest building in the world? \n",
            "\n",
            "A: The Burj Khalifa in Dubai, United Arab Emirates is the world's tallest building, standing at 829.8 meters (2,722 feet).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **様々なCompletionモデル**"
      ],
      "metadata": {
        "id": "G0Ze2mjgF2sV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   openai.Completion.create()ではGPT3,3.5,4系は使えない\n",
        "*   completionsエンドポイントをサポートしていないため"
      ],
      "metadata": {
        "id": "HYruOGflICYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **セクション3：プロンプトエンジニアリング**"
      ],
      "metadata": {
        "id": "eo92hhuzR4_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **良いプロンプトとは**"
      ],
      "metadata": {
        "id": "qY9b4HthU-0q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xqBvNjic2FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H5XlmO9_c2Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TcYlISrc1_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6kzGVlyc19V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cR0Kx5uRc1y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ow6s1tdU00P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijv4xTFK00Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdKo17LR00LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTHEUBWf00JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lCsBqjg00Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-kcwqKAJ00EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2IRYaeLwK-m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEK2bwadwbm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}